{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1oLbvkfivAuyTbKVbo7QQumsEeC7vHRY8",
      "authorship_tag": "ABX9TyOxd9vAC+uzY1yRu40JXg2V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qor0530/fontFinding/blob/main/fontfinding_to_deeplearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8i8QMk6qGxv"
      },
      "outputs": [],
      "source": [
        " #cnn 예제\n",
        "\n",
        " import sys\n",
        " import tensorflow as tf\n",
        " import keras\n",
        " from keras.models import Sequential\n",
        " from keras.layers import Dense, Dropout, Flatten\n",
        " from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        " import numpy as np\n",
        "\n",
        " img_rows = 28\n",
        " img_cols = 28\n",
        "\n",
        " (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        " input_shape = (img_rows, img_cols, 1)\n",
        " x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        " x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        " x_train = x_train.astype('float32') / 255.\n",
        " x_test = x_test.astype('float32') / 255.\n",
        "\n",
        " print('x_train shape:', x_train.shape)\n",
        " print(x_train.shape[0], 'train samples')\n",
        " print(x_test.shape[0], 'test samples')\n",
        "\n",
        " batch_size = 128\n",
        " num_classes = 10\n",
        " epochs = 1 #여러번 학습하면 좋겠지만 시간관계상 3번만 학습하고 결과를 확인합니다.\n",
        "\n",
        " y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        " y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        " model = Sequential()\n",
        " model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1), padding='same', activation='relu', input_shape=input_shape))\n",
        " model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        " model.add(Conv2D(64, (2, 2), activation='relu', padding='same'))\n",
        " model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        " model.add(Dropout(0.25))\n",
        " model.add(Flatten())\n",
        " model.add(Dense(1000, activation='relu'))\n",
        " model.add(Dropout(0.5))\n",
        " model.add(Dense(num_classes, activation='softmax'))\n",
        " model.summary()\n",
        "\n",
        " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " hist = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        " score = model.evaluate(x_test, y_test, verbose=0)\n",
        " print('Test loss:', score[0])\n",
        " print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습 딥러닝\n",
        "\n"
      ],
      "metadata": {
        "id": "KQzen4M4eM45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "plt.rc('font', family='NanumBarunGothic') \n",
        "\n",
        "unicode = 44032 #추출한 한글의 유니코드\n",
        "# for m in range(10,11173):\n",
        "fontobj = []\n",
        "  # for i in range(1,33):\n",
        "  #   df = pd.read_parquet(f'/content/drive/MyDrive/hangul-font-dataset-main/gothic/{i}.pq') #고딕 32까지 있음\n",
        "  #   fontobj.append(df.loc[unicode - 44032])\n",
        "for i in range(1,32):\n",
        "  df = pd.read_parquet(f'/content/drive/MyDrive/hangul-font-dataset-main/myeongjo/{i}.pq') #명조 31까지 있음\n",
        "  fontobj.append(df.loc[unicode - 44032])\n",
        "\n",
        "# 폰트 잘 나오는지 확인 코드\n",
        "fig = plt.figure(figsize=(64, 64))\n",
        "for i in range(1,55):\n",
        "  fontImage = fontobj[i-1][0]\n",
        "  image = Image.fromarray(fontImage.reshape([64, 64]))\n",
        "  ax1 = fig.add_subplot(1, 55, i)\n",
        "  ax1.set_xticks([])\n",
        "  ax1.set_yticks([])\n",
        "  ax1.set_title(f'{fontobj[i-1][9]}')\n",
        "  ax1.imshow(image, cmap='gray')\n",
        "fontfile = pd.DataFrame(fontobj)\n",
        "fontfile.to_csv(f'/content/drive/MyDrive/fontdata/{unicode}.csv')\n",
        "unicode += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "27BNtfn7201x",
        "outputId": "4c436144-17bf-4b11-9433-e5228d3e3202"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5911e4ff57fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mfontobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'/content/drive/MyDrive/hangul-font-dataset-main/gothic/{i}.pq'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#고딕 32까지 있음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mfontobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0municode\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m44032\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m         )\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             result = self.api.parquet.read_table(\n\u001b[0m\u001b[1;32m    240\u001b[0m                 \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             ).to_pandas(**to_pandas_kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyarrow/parquet/__init__.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2825\u001b[0m             )\n\u001b[1;32m   2826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2827\u001b[0;31m         return dataset.read(columns=columns, use_threads=use_threads,\n\u001b[0m\u001b[1;32m   2828\u001b[0m                             use_pandas_metadata=use_pandas_metadata)\n\u001b[1;32m   2829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyarrow/parquet/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m   2471\u001b[0m                 )\n\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m         table = self._dataset.to_table(\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter_expression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m             \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}